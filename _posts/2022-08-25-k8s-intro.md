---
title: 쿠버네티스 개요
author: guaqamole
date: 2022-08-25 18:32:00 -0500
categories: [Infra, Kubernetes]
tags: [Infra, Kubernetes, Container]
image:
  path: /common/k8s.png
---

인프라 엔지니어로 커리어를 시작하며 회사에서 사용하는 기술의 기본을 다지려고 한다. 쿠버네티스의 간단한 소개와 개요 느낌으로 아키텍처, 동작원리에 대해 설명하고, 최대한 내가 기억하기 쉽게 비유와 그림으로 설명해보려고 한다.

<br>

****



<br>

## **쿠버네티스가 뭔가요?**

공식문서가 정의한 쿠버네티스는 다음과 같다:

> 쿠버네티스는 **컨테이너화된 워크로드와 서비스를 관리**하기 위한 이식성이 있고, 확장가능한 오픈소스 플랫폼이다. 쿠버네티스는 **선언적 구성과 자동화를 모두 용이하게 해준다**. 쿠버네티스는 크고, 빠르게 성장하는 생태계를 가지고 있다. 쿠버네티스 서비스, 기술 지원 및 도구는 어디서나 쉽게 이용할 수 있다.
{: .prompt-info }

이처럼 쿠버네티스는 단순한 컨테이너 플랫폼이 아닌 마이크로서비스, 클라우드 플랫폼을 지향하고, 컨테이너로 이루어진 것들을 손쉽게 담고 관리할 수 있는 그릇 역할을 한다. 서버리스, CI/CD, 머신러닝 등 다양한 기능이 쿠버네티스 플랫폼 위에서 동작한다. 

1주일에 수십억 개의 컨테이너를 생성하는 Google이 내부 배포시스템으로 사용하던 'borg'를 기반으로 2014년 프로젝트를 시작했고, 여러 커뮤니티의 아이디어와 좋은 사례들을 모아 빠르게 발전했다. 이후 Google이 CNCF(Cloud Native Computing Foundation)에 코드를 기부함으로써, 쿠버네티스는 오픈 소스 프로젝트가 됐다. 

<br>

## **쿠버네티스의 등장배경**

<!-- ![](/230926/1.png){: width="800" height="600" } -->
![light mode only](/230926/1.png){: .light .w-95 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/1.png){: .dark .w-95 .shadow .rounded-50 w='800' h='600' }

### **전통적인 배포방식**

지금과는 많이 다른, 예전의 배포방식은 하나의 물리 서버에서 여러개의 애플리케이션을 배포하고 실행하는 방법이였다. 규모가 작은 서비스의 경우 큰 문제가 없겠지만, 서비스의 규모가 커지면 커질수록 비교적 리소스를 많이 차지하는 애플리케이션이 증가했을거다. 

하나의 애플리케이션 때문에 다른 인스턴스의 성능 저하가 발생하는것을 방지하기 위해, 여러개의 물리 서버를 둬서 리소스를 많이 차지하는 애플리케이션을 각 서버마다 분리시켜놨는데, 이때 당시 물리서버를 유지하는 데에 많은 비용이 들어갔다고 한다.

### **가상화된 배포 방식**

그 해결책으로 가상화가 도입됐다. 가상화란 하나의 물리 서버에서 여러 가상 머신(VM)을 실행할 수 있게 하는거다. 가상화를 사용하면 VM간에 애플리케이션을 격리하고 애플리케이션의 정보를 다른 애플리케이션에서 자유롭게 액세스할 수 없으므로, 일정 수준의 보안적 편의성도 제공했다.

가상화를 사용하면 물리 서버에서 리소스를 보다 효율적으로 활용할 수 있었고, 쉽게 애플리케이션을 배포하거나 업데이트할 수 있었으며, 하드웨어 비용까지 절감할 수 있어 더 나은 확장성을 제공했다. 

### **컨테이너화된 개발 방식**

그 이후 컨테이너라는 기술이 새롭게 소개되었는데, 컨테이너는 VM과 유사하지만 VM보다 격리 환경이 완화되어 애플리케이션 간에 운영체제(OS)를 공유할수 있게된다. 그러므로 컨테이너는 VM보다 경량화 되었다고 말한다. VM과 마찬가지로 컨테이너에는 자체 파일 시스템, CPU 점유율, 메모리, 프로세스 공간 등이 있으며, 인프라간의 종속성을 끊었기 때문에, 클라우드나 OS 배포본에 모두 이식할 수 있다.

### **쿠버네티스가 왜 필요한가**

컨테이너라는 기술은 애플리케이션을 배포하고 실행하는 좋은 방법이다. 운영 환경에서는 실시간으로 애플리케이션 컨테이너를 관리하고 `Down-Time`이 없는지 확인해야 한다. 

예를 들어, 운영중인 서비스의 DB 컨테이너가 다운되면 해당 컨테이너에 종속된 다른 컨테이너들 또한 다시 시작해야 하는데, ***이 과정을 시스템이 자동으로 처리해준다면 더 쉽게 서비스를 운영할 수 있지 않을까요?***

**이것이 바로 쿠버네티스가 필요한 이유이다**. 컨테이너화된 개발 방식으로 넘어가는 시대에, 쿠버네티스는 분산 시스템을 탄력적으로 실행하기 위한 프레임 워크를 제공한다. 애플리케이션의 확장과 장애 대응에 유능하고, 다양한 배포 방식까지 제공한다 (예시로, 쿠버네티스는 카나리아 배포방식을 쉽게 적용 할 수 있다).

<br>

## **쿠버네티스가 제공하는 기능**

### **1. Service Discovery & Load Balancing**

MSA와 같은 분산 환경은 서비스간의 원격 호출로 구성이 된다.

원격 서비스 호출은 IP 주소와 포트를 이용하는 방식이 있는데:

- 클라우드 환경으로 변하면서 서비스가 **오토 스케일링 등에 의해 동적으로 생성**되거나,

- **컨테이너 기반의 배포로 인해 서비스의 IP가 동적으로 변경**되는 일이 잦아졌다.

 그래서 **서비스 Client가 서비스를 호출할 때 서비스의 위치 (즉 IP주소와 포트)를 알아낼 수 있는 기능**이 필요한데, 이것을 바로 **서비스 디스커버리**라고 한다.

![](/230926/2.png){: width="600" height="500" }
_https://bcho.tistory.com/1252_

- Service A의 인스턴스들이 생성이 될때, Service A에 대한 주소를 Service registry (서비스 등록 서버)에 등록해놓는다.

- Service A를 호출하고자 하는 클라이언트는 Service registry에 Service A의 주소를 물어보고 등록된 주소를 받아서 그 주소로 서비스를 호출한다.

#### **Client Side Discovery**

![](/230926/3.png){: width="600" height="500" }
_https://mangchhe.github.io/springcloud/2021/04/07/ServiceDiscoveryConcept/_

생성된 서비스는 Service Registry에 서비스를 등록하고

서비스를 사용할 클라이언트는 Service Registry에서 서비스의 위치를 찾아 호출하는 방식이다.

대표적으로 `Netflix OSS`(Netflix Open Source Software)에서 Client-Side discovery Pattern을 제공하는 Netflix Eureka가 Service Registry 역할을 하는 OSS이다.

#### **Server Side Discovery**

![](/230926/4.png){: width="600" height="500" }
_https://mangchhe.github.io/springcloud/2021/04/07/ServiceDiscoveryConcept/_

서비스를 사용할 클라이언트와 Service Registry 사이에 일종의 Proxy 서버인 Load Balancer를 두는 방식이다.

클라이언트는 Load Balancer에 서비스를 요청하고

Load Balancer가 Service Registry에 호출할 서비스의 위치를 질의하는 방식이다.

AWS의 `ELB`나 GCP의 `LoadBalancer`가 대표적이다.

<br>

### **2. Storage Orchestration**

![light mode only](/230926/5.png){: .light .w-75 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/5.png){: .dark .w-75 .shadow .rounded-50 w='800' h='600' }

쿠버네티스(Kubernetes) 환경에서 구동되는 애플리케이션에서 보다 손쉽게 스토리지를 사용할 수 있도록 `Storage Orchestration CSI`라는것이 존재한다. 

쿠버네티스에서 스토리지 볼륨을 사용하는 방식은 PV(Persistent Volume), SC(Storage Class)라는 객체를 이용하여 생성하고 관리한다. 

하지만 PV, SC를 사용하는 것만으로는 스토리지 내 볼륨을 생성하고 변경할 수 없다. 이러한 문제를 해결하기 위해서 Storage Orchestration CSI는 쿠버네티스에서 제공하는 CSI(Container Storage Interface)라는 표준 라이브러리를 기반으로, 쿠버네티스 환경에서 스토리지 통합 제어가 가능하도록 만든 솔루션이다. 이를 통해 사용자는 SC 구성 후 PV를 생성하는 것만으로도 스토리지 내 볼륨 생성, 변경이 가능하다.

<br>

### **3. Automated rollout & rollback**

![light mode only](/230926/6.png){: .light .w-85 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/6.png){: .dark .w-85 .shadow .rounded-50 w='800' h='600' }

쿠버네티스를 사용하여 배포된 컨테이너의 원하는 상태를 트래킹 할 수 있으며 현재 상태를 원하는 상태로 설정한 대로 변경할 수 있다. 예를 들어 쿠버네티스에선 배포용 1.새 컨테이너를 만들고, 2.기존 컨테이너를 제거하고, 3. 모든 리소스를 새 컨테이너에 적용할 수 있는 기능을 제공한다. 다음은 쿠버네티스에서 어떤 방식으로 애플리케이션을 배포하고 업데이트하는지 알아보겠다.

#### **Rolling Updates**

서버를 실제로 서비스할 때 서비스적인 장애와 배포에 있어서 부담감을 최소화하고, 서비스가 중단되지 않도록 배포하는 **무중단 배포** 방법 중 하나이다.

새 버전을 배포하면서, 새 버전 인스턴스를 하나씩 늘려가고 기존 버전의 인스턴스를 하나식 줄여나가는 방식이다.

새 버전의 인스턴스로 트래픽이 이전되기 전까지 이전 버전과 새 버전의 인스턴스가 동시에 존재할 수 있다는 단점이 있지만, 시스템을 무중단으로 업데이트할 수 있다.

 

deployment 생성 시 strategy를 지정하지 않으면 rolling update 방식으로 배포하는 것으로 간주한다.

두 방식의 동작 차이는 `describe deployment` 명령으로도 확인할 수 있다.

~~~shell
kubectl describe deployment <NAME>
~~~

#### **Rollouts**

애플리케이션 컨테이너를 점진적으로 배포하거나 업그레이드하는 프로세스이다.

새 deployment를 생성하거나 기존 deployment의 이미지를 업그레이드할 때마다 트리거 된다.

애플리케이션 업그레이드 시 새로운 `rollout`이 트리거 되고, 이 `rollout`이 새로운 버전의 deployment를 생성한다.

또한 deployment의 변경 사항을 확인하고, 이전 버전의 deployment로 되돌릴 수 있게 한다.

~~~shell
# rollout 상태 확인
kubectl rollout status deployment/<NAME>

# rollout 이력 확인
kubectl rollout history deployment/<NAME>
~~~

#### **Upgrade**

도커 컨테이너 버전, 레이블, replicas 수를 수정하는 등의 작업이 있을 수 있다.

쿠버네티스에선 보통 yaml 형식의 deployment 정의 파일을 수정한 뒤, `apply` 명령으로 반영한다.

~~~shell
kubectl apply -f <FILE>
~~~

deployment에 사용하는 이미지를 수정하는 경우에는, 아래와 같이 set 명령어를 사용할 수도 있다.

~~~shell
kubectl set image deployment/<DEPLOYMENT_NAME> <CONTAINER_NAME>=<IMAGE>

# 예시
kubectl set image deployment/my-app nginx=nginx:1.9.1
~~~

이 경우 기존 정의 파일과 구성이 달라지기 때문에, 추후 정의 파일을 재사용할 때 주의해야 한다.

 

업그레이드를 진행하면 쿠버네티스 deployment 개체가 새 replicaset를 생성하고 컨테이너를 배치한다. 그리고 update Strategy에 따라 이전 replicaset의 pod를 중단한다.

이전 replicaset의 포드 수나 새 resplicaset의 포드 수 등에 대한 정보는 `kubectl get replicasets`  명령어로 확인할 수 있다.

#### **Rollback**

애플리케이션 업데이트 후 문제가 발생하여, 업데이트를 되돌리고 싶다면 rollout undo 명령을 사용하면 된다.

~~~shell
kubectl rollout undo deployment/<NAME>
~~~

`rollout undo` 명령을 실행하면 새로 생성한 replicaset의 pod는 삭제하고, 이전 replicaset의 pod를 다시 생성한다.

<br>

###  **4. Resource bin-packing**

자동화된 빈 패킹은 쿠버네티스의 컨테이너 스케줄링 기능 중 하나로

**컨테이너를 클러스터의 노드에 효율적으로 배포하는 기능을 말한다.** 

쿠버네티스는 여러 대의 컴퓨터(노드)에서 컨테이너를 실행하는데, 각 노드에는 자원(예: CPU, 메모리)이 제한적이기 때문에 컨테이너를 효율적으로 배치하는 것이 중요한다. 이때 자동화된 빈 패킹은 컨테이너를 노드에 최대한 적절하게 배치하여 자원을 효율적으로 사용한다.

#### **MostAllocated 전략**

`MostAllocated` 전략은 리소스 사용량을 기반으로 할당량이 많은 노드를 높게 평가하여 노드에 점수를 매기게 된다. 각 리소스 유형별로 가중치를 설정하여 노드 점수에 미치는 영향을 조정할 수 있다.

**가중치 계산 예시**

요청된 리소스:
~~~yaml
intel.com/foo : 2
memory: 256MB
cpu: 2
~~~

리소스 가중치:
~~~yaml
intel.com/foo : 5
memory: 1
cpu: 3
~~~

노드 1의 사양:
~~~yaml
Available:
  intel.com/foo: 4
  memory: 1 GB
  cpu: 8

Used:
  intel.com/foo: 1
  memory: 256MB
  cpu: 1
~~~

노드 점수:
~~~yaml
intel.com/foo  = resourceScoringFunction((2+1),4)
               = (100 - ((4-3)*100/4)
               = (100 - 25)
               = 75                       # requested + used = 75% * available
               = rawScoringFunction(75) 
               = 7                        # floor(75/10) 

memory         = resourceScoringFunction((256+256),1024)
               = (100 -((1024-512)*100/1024))
               = 50                       # requested + used = 50% * available
               = rawScoringFunction(50)
               = 5                        # floor(50/10)

cpu            = resourceScoringFunction((2+1),8)
               = (100 -((8-3)*100/8))
               = 37.5                     # requested + used = 37.5% * available
               = rawScoringFunction(37.5)
               = 3                        # floor(37.5/10)

NodeScore   =  (7 * 5) + (5 * 1) + (3 * 3) / (5 + 1 + 3)
            =  5
~~~

<br>

### **5. Self-healing**

- 파드의 자동 복구 기술
- 제대로 작동하지 않는 컨테이너를 다시 시작하거나 교체해 파드가 정상적으로 작동하게 한다.

쿠버네티스는 애플리케이션의 안정성을 위해 `자동 복구` 기능을 제공한다. 쿠버네티스는 애플리케이션을 지속적으로 모니터링하며, 어떤 노드나 컨테이너가 장애가 발생하면, 자동으로 해당 컨테이너를 복구하거나 새로운 컨테이너를 생성하여 문제를 해결한다.

<br>

## **쿠버네티스 아키텍처**

### **전체 구조**

![light mode only](/230926/7.png){: .light .w-85 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/7.png){: .dark .w-85 .shadow .rounded-50 w='800' h='600' }

쿠버네티스의 단위는 **클러스터**이다. 그리고 쿠버네티스 클러스터는 컨트롤 플레인(Control Plane)과 워커 노드(Worker Node)로 나누어볼 수 있다. 컨트롤 플레인은 클러스터의 제어를 담당하며, 워커 노드는 애플리케이션 컨테이너를 실행하고 관리하는 데 사용된다.

#### **네임스페이스 (Namespace)**

하나의 클러스터 안에는 여러 네임스페이스를 만들 수 있다. 클러스터가 비교적 물리적인 단위라면 네임스페이스는 논리적인 격리 단위이다. 네임스페이스를 사용하여 다수의 팀이나 프로젝트가 동일한 클러스터 내에서 자원을 분리하여 사용할 수 있다. 각 네임스페이스는 해당 네임스페이스 내에서만 고유한 리소스 이름을 가질 수 있으므로, 리소스 간의 충돌을 방지하고 격리된 환경을 제공한다.

#### **동작 원리**

쿠버네티스 컴포넌트를 크게 분류하면, **컨트롤 플레인**(Control Plane)과 **워커 노드**(Worker Node)로 나누어볼 수 있다. 쿠버네티스를 배를 타는 크루와 관련하여 다음과 같이 비유를 들어 보겠다.

컨트롤 플레인(Control Plane)은 ***배의 선장***과 같다. 선장은 항해 경로를 결정하고, 목표지점에 도착하기 위한 계획을 수립한다. 마찬가지로, 컨트롤 플레인은 클러스터의 상태를 모니터링하고, 클러스터 전체의 조작을 수행하여 원하는 상태로 유지한다.

워커 노드(Worker Node)는 ***배의 선원들***이다. 선원들은 선장의 명령에 따라 필요한 작업을 수행하며, 배가 안전하고 원활하게 항해하도록 도와준다. 워커 노드도 마찬가지로, 컨트롤 플레인에서 전달받은 지시에 따라 컨테이너를 실행하고, 애플리케이션을 관리하며, 리소스를 적절하게 사용하여 클러스터를 운영한다.

이렇게 생각해보면, 쿠버네티스는 바다를 항해하는 큰 배처럼 컨테이너화된 애플리케이션을 운영하고, 리소스를 관리하여 원하는 목표 지점(상태)에 도달할 수 있도록 지원한다는 의미를 더욱 쉽게 이해할 수 있다.

<br>

### **컨트롤 플레인(Control Plane)**

![light mode only](/230926/8.png){: .light .w-75 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/8.png){: .dark .w-75 .shadow .rounded-50 w='800' h='600' }

컨트롤 플레인은 쿠버네티스 클러스터의 중앙 관리 및 제어 부분으로, 클러스터의 상태를 모니터링하고 관리하는 중요한 구성 요소들을 포함한다. 컨트롤 플레인에 속해 있는 컴포넌트들은 다음과 같다:

#### **kube-apiserver**

![light mode only](/230926/9.png){: .light .w-75 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/9.png){: .dark .w-75 .shadow .rounded-50 w='800' h='600' }

공식 문서에서는 `kube-apiserver`를 ‘***쿠버네티스 컨트롤 플레인의 프론트엔드***’ 라고 소개하고 있다. kube-apiserver는 쿠버네티스 클러스터로 들어오는 요청을 가장 앞에서 접수하는 “대문” 역할을 하졌다. 쿠버네티스 명령어 도구인 kubectl을 사용해 수행되는 명령은 kube-apiserver로 전송된다.

#### **etcd**

![light mode only](/230926/10.png){: .light .w-75 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/10.png){: .dark .w-75 .shadow .rounded-50 w='800' h='600' }

etcd는 클러스터가 동작하는 데 필요한 리소스의 구성 정보, 상태 및 명세 정보 등 모든 설정 데이터들을 key-value 형태로 저장하는 저장소이다. api를 통해 전달받은 리소스 정보를 여기 etcd에 저장하졌다. 안정적인 동작을 위해 자료를 분산해서 저장하여 쿠버네티스의 신뢰성과 안정성을 제공한다.

#### **kube-scheduler**

![light mode only](/230926/12.png){: .light .w-80 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/12.png){: .dark .w-80 .shadow .rounded-50 w='800' h='600' }

쿠버네티스 클러스터는 여러 노드로 구성되어 있고, 파드(Pod)는 여러 노드 중 특정 노드에 배치되어 동작하게 된다. 이때 새로 생성된 파드를 감지해 적절한 노드로 배치하는 작업을 스케줄링이라고 한다. kube-scheduler는 이런 스케줄링을 담당하는 컴포넌트이다. 새로운 파드를 적절하게 분산시키고, 리소스를 효율적으로 사용하여 클러스터의 성능과 안정성을 유지하는데 기여한다.
\* 파드(Pod)는 쿠버네티스에서 가장 작은 배포 단위로서, 하나 이상의 컨테이너들을 묶어서 함께 실행하는 그룹이다.

#### **kube-controller-manager**

![light mode only](/230926/11.png){: .light .w-80 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/11.png){: .dark .w-80 .shadow .rounded-50 w='800' h='600' }

클러스터의 상태를 지속적으로 모니터링하고, 원하는 상태로 유지하기 위해 관리하는 것이 kube-controller-manager 이다. 노드가 정상적으로 작동하는지, 파드가 의도한 복제본(replica) 개수를 유지하고 있는지, 서비스와 파드가 적절하게 연결되어 있는지 등의 역할을 하고 있다.

<br>

### **워커노드 (Worker Node)**

#### **kubelet**

![light mode only](/230926/13.png){: .light .w-80 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/13.png){: .dark .w-80 .shadow .rounded-50 w='800' h='600' }

kubelet(큐브릿)은 마스터 노드로부터 받은 명령을 따라 컨테이너를 관리하고 노드 상태를 보고하는 역할을 한다. kubectl 명령어를 사용하면, 파드를 관리하기 위해 작성하는 YAML이 kube-apiserver로 전송된 후 kubelet으로 전달된다. kubelet은 YAML을 통해 전달된 파드를 생성 또는 변경하고, YAML에 명시된 컨테이너가 정상적으로 실행되는지 확인하며 파드 안의 컨테이너들을 관리한다.

1. **container runtime:**
   컨테이너 런타임은 컨테이너를 시작하고 실행하는 역할을 한다. 대표적으로 도커(docker)가 있고, 컨테이너디(containerd), 크리오(CRI-O) 등이 있다.
2. **kube-proxy:**
   kube-proxy는 쿠버네티스 클러스터 내부에서 네트워크 요청을 전달하는 역할을 한다. 파드 IP는 파드가 배포될 때마다 매번 변하지만, kube-proxy가 이 파드에 접근할 수 있는 방법을 갱신하고, 서비스 오브젝트는 이 정보를 통해 파드가 외부에서 접근할 수 있는 경로를 제공한다.

![light mode only](/230926/14.png){: .light .w-80 .shadow .rounded-50 w='800' h='600' }
![dark mode only](/230926/14.png){: .dark .w-80 .shadow .rounded-50 w='800' h='600' }


<br>

## Reference
- https://kubernetes.io/ko/docs/concepts/overview/
- https://nice-engineer.tistory.com/entry/Kubernetes-Service-Discovery
- https://coffeewhale.com/apiserver
- https://kubernetes.io/ko/docs/concepts/scheduling-eviction/resource-bin-packing/
- https://calsoftinc.com/blogs/2019/08/simplify-storage-for-kubernetes-with-rook-and-ceph.html
- https://sharplee7.tistory.com/84
- https://www.samsungsds.com/kr/techreport/storage-orchestration.html